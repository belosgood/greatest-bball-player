{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project01\n",
    "\n",
    "Jen Lee & Isabel Osgood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Objective\n",
    "\n",
    "Our experiment attempts to answer the age-old controversy ‘Who is the best basketball player of all time?’. Well, not really. We are going to use the NBA career stats of Michael Jordan, Kobe Bryant, and Lebron James to create a classification algorithm for each of the basketball greats. In a way, we are testing to see if we can build an algorithm to find a difference between these players stats. \n",
    "\n",
    "### Data Source\n",
    "\n",
    "We were able to get a dataset of the advanced stats of James, Jordan, and Bryant from Kaggle where the dataset was listed as being public domain.\n",
    "\n",
    "The dataset can be found [here](https://www.kaggle.com/xvivancos/michael-jordan-kobe-bryant-and-lebron-james-stats) and the Terms of Use can be found [here](https://www.kaggle.com/terms). Section 5 states that we promise to abide by \"all copyright notices, trademark rules, information, and restrictions contained in any Content you access through the Services.\" but because we have no plans to exploit this content andnin addition to most NBA data being widely available there is no ethical restrictions in using this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Lg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>...</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>Player</th>\n",
       "      <th>RSorPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-04</td>\n",
       "      <td>19</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NBA</td>\n",
       "      <td>SG</td>\n",
       "      <td>79</td>\n",
       "      <td>3122</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.145</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.078</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Lebron James</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>20</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NBA</td>\n",
       "      <td>SF</td>\n",
       "      <td>80</td>\n",
       "      <td>3388</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.183</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.203</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Lebron James</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>21</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NBA</td>\n",
       "      <td>SF</td>\n",
       "      <td>79</td>\n",
       "      <td>3361</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.208</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.232</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Lebron James</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-07</td>\n",
       "      <td>22</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NBA</td>\n",
       "      <td>SF</td>\n",
       "      <td>78</td>\n",
       "      <td>3190</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.191</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.206</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Lebron James</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-08</td>\n",
       "      <td>23</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NBA</td>\n",
       "      <td>SF</td>\n",
       "      <td>75</td>\n",
       "      <td>3027</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.219</td>\n",
       "      <td>...</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.242</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>Lebron James</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Age   Tm   Lg Pos   G    MP   PER    TS%   3PAr  ...   OWS  DWS  \\\n",
       "0  2003-04   19  CLE  NBA  SG  79  3122  18.3  0.488  0.145  ...   2.4  2.6   \n",
       "1  2004-05   20  CLE  NBA  SF  80  3388  25.7  0.554  0.183  ...   9.7  4.6   \n",
       "2  2005-06   21  CLE  NBA  SF  79  3361  28.1  0.568  0.208  ...  12.0  4.3   \n",
       "3  2006-07   22  CLE  NBA  SF  78  3190  24.5  0.552  0.191  ...   8.0  5.7   \n",
       "4  2007-08   23  CLE  NBA  SF  75  3027  29.1  0.568  0.219  ...  10.7  4.6   \n",
       "\n",
       "     WS  WS/48  OBPM  DBPM   BPM  VORP        Player          RSorPO  \n",
       "0   5.1  0.078   2.2  -0.2   1.9   3.1  Lebron James  Regular Season  \n",
       "1  14.3  0.203   6.9   1.5   8.3   8.8  Lebron James  Regular Season  \n",
       "2  16.3  0.232   7.9   1.4   9.3   9.5  Lebron James  Regular Season  \n",
       "3  13.7  0.206   5.4   2.0   7.4   7.6  Lebron James  Regular Season  \n",
       "4  15.2  0.242   9.0   2.3  11.2  10.1  Lebron James  Regular Season  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load in the data from a saved csv file\n",
    "bball = pd.read_csv('advanced_stats.csv')\n",
    "\n",
    "# Print head to show success\n",
    "bball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The data contains 29 columns, and __ were dropped for the follwoing reasons:\n",
    "\n",
    "* Season - a baises variables, as the machine would quickly learn what time range of each player \n",
    "\n",
    "* Age - again biases, Kobe is the only player with data at age 18 while Jordan had the longest career, playing until 40. To reserve data it was best to eliminate \n",
    "\n",
    "* Team - also a biased variable\n",
    "\n",
    "* Lg - dropped because every row says NBA, thus useless\n",
    "\n",
    "* Pos - biased variable\n",
    "\n",
    "For the following dropped variables, we consulted a basketball expert who explained how each stat is measured and what it truely says about a players performance. \n",
    "\n",
    "* OWS, DWS, WS/48 (Offensive Win Shares), (Defensive Win Shares), (Win Shares Per 48 Minutes) - The way these are calculated we felt was repetatitve of Total Win Shares and to keep all four features would be unnecessary. \n",
    "\n",
    "\n",
    "* OBPM (Offensive Box Plus/Minus), DBPM (Defensive Box Plus/Minus) - This is calcuated very similarly to WS and only the combined BPM scores was kept. \n",
    "\n",
    "* RSorPO (Regular Season or Playoffs) - Because this is a team not individual statistic it was dropped. \n",
    "\n",
    "\n",
    "| Player | Classification |\n",
    "| ----------- | ----------- |\n",
    "| Kobe Bryan | 0 |\n",
    "| Lebron James | 1 |\n",
    "| Michael Jordan | 2 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>Player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>3122</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.308</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.9</td>\n",
       "      <td>28.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>3388</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.378</td>\n",
       "      <td>3.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>32.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>3361</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.447</td>\n",
       "      <td>2.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>32.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>33.6</td>\n",
       "      <td>16.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>3190</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>29.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>3027</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.470</td>\n",
       "      <td>4.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>33.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    G    MP   PER    TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  \\\n",
       "0  79  3122  18.3  0.488  0.145  0.308   3.5  11.8   7.6  27.8   2.2   1.3   \n",
       "1  80  3388  25.7  0.554  0.183  0.378   3.8  17.0  10.2  32.9   2.8   1.1   \n",
       "2  79  3361  28.1  0.568  0.208  0.447   2.6  17.1   9.8  32.8   2.0   1.5   \n",
       "3  78  3190  24.5  0.552  0.191  0.432   3.0  16.6   9.6  29.1   2.1   1.3   \n",
       "4  75  3027  29.1  0.568  0.219  0.470   4.9  17.8  11.1  37.3   2.4   2.1   \n",
       "\n",
       "   TOV%  USG%    WS   BPM  VORP  Player  \n",
       "0  13.9  28.2   5.1   1.9   3.1       1  \n",
       "1  11.8  29.7  14.3   8.3   8.8       1  \n",
       "2  10.7  33.6  16.3   9.3   9.5       1  \n",
       "3  11.5  31.0  13.7   7.4   7.6       1  \n",
       "4  11.4  33.5  15.2  11.2  10.1       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball.drop(bball.iloc[:, 0:5], inplace = True, axis = 1)\n",
    "bball.drop(['OWS', 'DWS', 'WS/48', 'OBPM', 'DBPM', 'RSorPO'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "bball.isnull().values.any()\n",
    "\n",
    "# convert classes (players) to integers \n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(bball['Player']))}\n",
    "class_mapping\n",
    "bball['Player'] = bball['Player'].map(class_mapping)\n",
    "\n",
    "# Print head to show success\n",
    "bball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split\n",
    "\n",
    "**TODO: Inclde training vs test decisions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = bball.iloc[:, 0:16].values, bball.iloc[:, 17].values\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.3, \n",
    "                     random_state=0, \n",
    "                     stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "**TODO: Include decision on what features to add to model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 3PAr                           0.163660\n",
      " 2) BPM                            0.151492\n",
      " 3) DRB%                           0.150320\n",
      " 4) TRB%                           0.140267\n",
      " 5) STL%                           0.076613\n",
      " 6) PER                            0.066969\n",
      " 7) ORB%                           0.045354\n",
      " 8) TOV%                           0.041698\n",
      " 9) AST%                           0.041419\n",
      "10) USG%                           0.034493\n",
      "11) BLK%                           0.022750\n",
      "12) FTr                            0.015986\n",
      "13) TS%                            0.015539\n",
      "14) WS                             0.013220\n",
      "15) MP                             0.010673\n",
      "16) G                              0.009546\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#select features using random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_labels = bball.columns[:16]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                                random_state=1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player\n",
      "0    0.213714\n",
      "1    0.220241\n",
      "2    0.079571\n",
      "Name: 3PAr, dtype: float64\n",
      "Player\n",
      "0     3.037143\n",
      "1    10.062069\n",
      "2     8.653571\n",
      "Name: BPM, dtype: float64\n",
      "Player\n",
      "0    12.311429\n",
      "1    19.486207\n",
      "2    13.950000\n",
      "Name: DRB%, dtype: float64\n",
      "Player\n",
      "0     7.722857\n",
      "1    11.858621\n",
      "2     9.325000\n",
      "Name: TRB%, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(bball.groupby(['Player'])['3PAr'].mean())\n",
    "print(bball.groupby(['Player'])['BPM'].mean())\n",
    "print(bball.groupby(['Player'])['DRB%'].mean())\n",
    "print(bball.groupby(['Player'])['TRB%'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features that meet this threshold criterion: 4\n",
      " 1) 3PAr                           0.163660\n",
      " 2) BPM                            0.151492\n",
      " 3) DRB%                           0.150320\n",
      " 4) TRB%                           0.140267\n",
      "[4, 15, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(forest, threshold=0.1, prefit=True)\n",
    "X_selected = sfm.transform(X_train)\n",
    "print('Number of features that meet this threshold criterion:', \n",
    "      X_selected.shape[1])\n",
    "\n",
    "features = []\n",
    "for f in range(X_selected.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "    # Keek track of feature indices\n",
    "    features.append(indices[f])\n",
    "    \n",
    "# TODO: Delete later\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "### Classification Algorithm 1: K Nearest Neighbor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5\n",
      "Test accuracy: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Original training set accuracy\n",
    "knn.fit(X_train, y_train)\n",
    "print('Training accuracy:', knn.score(X_train, y_train))\n",
    "print('Test accuracy:', knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.875\n",
      "Test accuracy: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Accuracy with __ most relevant features\n",
    "knn.fit(X_train[:, features], y_train)\n",
    "print('Training accuracy:', knn.score(X_train[:, features], y_train))\n",
    "print('Test accuracy:', knn.score(X_test[:, features], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Algorithm 2: Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Function taken from examples/ch05\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    labels = ('Bryant', 'James', 'Jordan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot examples by class\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.6, \n",
    "                    color=cmap(idx),\n",
    "                    edgecolor='black',\n",
    "                    marker=markers[idx], \n",
    "                    label=labels[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Use PCA to reduce the dimension of X\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "\n",
    "lr = LogisticRegression(multi_class='ovr', random_state=1, solver='lbfgs')\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "print(lr.score(X_train_pca, y_train)) #training accuracy \n",
    "lr.score(X_test_pca, y_test) #test accuracy \n",
    "\n",
    "# Plot Train\n",
    "# plot_decision_regions(X_train_pca, y_train, classifier=lr)\n",
    "# plt.xlabel('PC 1')\n",
    "# plt.ylabel('PC 2')\n",
    "# plt.legend(loc='lower left')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Test \n",
    "# plot_decision_regions(X_test_pca, y_test, classifier=lr)\n",
    "# plt.xlabel('PC 1')\n",
    "# plt.ylabel('PC 2')\n",
    "# plt.legend(loc='lower left')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=16, \n",
    "                                random_state=1,\n",
    "                                n_jobs=2)\n",
    "rf = forest.fit(X_train, y_train)\n",
    "\n",
    "print(rf.score(X_train, y_train)) #training accuracy\n",
    "print(rf.score(X_test, y_test)) #test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "rf_sub = forest.fit(X_train[:, features], y_train)\n",
    "\n",
    "print(rf_sub.score(X_train[:, features], y_train)) #training accuracy\n",
    "print(rf_sub.score(X_test[:, features], y_test)) #test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Models \n",
    "   ### using confusion matrixes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nearest Neighbor method:\n",
      "Training accuracy: 0.875\n",
      "Test accuracy: 0.7857142857142857\n",
      "Precision: 0.852\n",
      "Recall: 0.766\n",
      "F1: 0.775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "#KNN \n",
    "print('K-nearest Neighbor method:')\n",
    "print('')\n",
    "# Accuracy with __ most relevant features\n",
    "knn.fit(X_train[:, features], y_train)\n",
    "print('Training accuracy:', knn.score(X_train[:, features], y_train))\n",
    "print('Test accuracy:', knn.score(X_test[:, features], y_test))\n",
    "\n",
    "y_pred = knn.predict(X_test[:, features])\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression:\n",
      "\n",
      "Training accuracy: 0.71875\n",
      "Test accuracy: 0.7142857142857143\n",
      "Precision: 0.711\n",
      "Recall: 0.683\n",
      "F1: 0.658\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print('Logisitic Regression:')\n",
    "print('')\n",
    "# Accuracy with __ most relevant features\n",
    "lr.fit(X_train_pca, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_pca, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_pca, y_test))\n",
    "\n",
    "y_pred = lr.predict(X_test_pca)\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "Training Accuracy: 1.0\n",
      "Test accuracy: 0.9642857142857143\n",
      "Precision: 0.972\n",
      "Recall: 0.963\n",
      "F1: 0.966\n",
      "RANDOM FOREST WAS THE MOST SUCCESFUL MODEL FOR THIS PROBLEM\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "print('Random Forest')\n",
    "print('')\n",
    "rf = forest.fit(X_train, y_train)\n",
    "\n",
    "print('Training Accuracy:', rf.score(X_train, y_train)) #training accuracy\n",
    "print('Test accuracy:', rf.score(X_test, y_test)) #test accuracy\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average = 'macro'))\n",
    "\n",
    "print('RANDOM FOREST WAS THE MOST SUCCESFUL MODEL FOR THIS PROBLEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Summary\n",
    "\n",
    "In the course of building our model, random forest was the most successful algorithm for this problem. Looking at the data post-hoc this makes sense because our classes do not have a defined linear divide. Using random forest, we were able to accurately model the differences between Kobe Bryant, Michael Jordan, and Lebron James. The accuracy of this model actaully exceeded our expectations. \n",
    "On a side note we took the 4 most important features (the features that meet the .10 threshold of feature importancce), and looked at each player's career average in those stats and LeBron James outperformed both Bryant and Jordan in all four metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish summary (idk what else there is to say?) More in depth about the models maybe \n",
    "We need say something about our train test split I think. \n",
    "Just reread the instructions and see if anything is missing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
